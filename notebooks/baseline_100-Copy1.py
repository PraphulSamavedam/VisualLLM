import json
import numpy as np
import pandas as pd
from tqdm import tqdm
from transformers import pipeline
from huggingface_hub import login

# Setup
validation_folder = "../data/validation"
annotations_file_path = f"{validation_folder}/annotations.json"
questions_file_path = f"{validation_folder}/questions.json"
token = "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"
login(token=token) ## This is bound to fail, add your token from chat and run

print("Obtaining the images to annotations")
# Load annotations and questions
with open(annotations_file_path, 'r') as file:
    annotations_data = json.load(file)['annotations']
with open(questions_file_path, 'r') as file:
    questions_data = json.load(file)['questions']

# Convert to numpy arrays for efficient operations
annotations = np.array(annotations_data)
questions = np.array(questions_data)

# Sample random 100 annotations and questions
indices = np.random.choice(len(annotations), 10000, replace=False)
annotations_data = annotations[indices]
questions_data = questions[indices]

print("Prepare data")
# Prepare data
data = [{
    "Image ID": annotation_info["image_id"],
    "Image file": f"../data/validation/images/COCO_val2014_{str(annotation_info['image_id']).zfill(12)}.jpg",
    "Question ID": annotation_info["question_id"],
    "Question": questions_data[indx]['question'],
    "Answer": annotation_info['multiple_choice_answer'],
    "Plausible answers": set(x['answer'] for x in annotation_info['answers']),
    "Question Type": annotation_info['question_type'],
    "Answer Type": annotation_info['answer_type']
} for indx, annotation_info in enumerate(annotations_data)]

# results = [{"question_id":  annotation_info["question_id"],
#             "question": questions_data[indx]['question'], 
#             "answer": annotation_info['multiple_choice_answer'],
#             "plausible_answers": plausile_answers,
#                                "image_id": annotation_info['image_id'], "question_type" :annotation_info['question_type'],
#                                "answer_type": annotation_info['answer_type']}]
# results.append()

# Write data to a CSV file
df = pd.DataFrame(data)
df.to_csv('../data/10k_mapped_question_answers.csv', index=False)


print("Running BLIP")
# Generate captions using Blip Pipeline
blipPipe = pipeline("image-to-text", model="Salesforce/blip-image-captioning-base", device='cuda', max_new_tokens=15)
df["Generated Caption"] = [x[0]['generated_text'] for x in blipPipe(df["Image file"].tolist())]

print("Storing Captions")
# Write data to a CSV file
df[['Image file', 'Generated Caption']].to_csv('10k_blip_captions.csv', index=False)

# Create a lookup dictionary
lookup = df.set_index('Image ID')[['Image file', 'Generated Caption']].T.to_dict('list')



# Initialize Llama pipeline
llamaPipe = pipeline("text-generation", model="meta-llama/Llama-2-7b-chat-hf", device='cuda')

print("Running Zero shot on LLama")
# Zero Shot Performance with 20 tokens
answers = [{
    'Image ID': instance['Image ID'],
    'Caption': lookup[instance['Image ID']][1],
    'Question': instance['Question'],
    'Prompt': f"Based on the image caption (generated by BLIP model): {lookup[instance['Image I']][1]}, Answer the question '{instance['Question']}' \n Answer: ",
    'Generated Answer': llamaPipe(prompt, max_new_tokens=20)[0]['generated_text']
} for instance in tqdm(results)]

# Write data to a CSV file
pd.DataFrame(answers).to_csv('10k_default_answers.csv', index=False)

# Zero Shot Performance with configuration limit only
print("Running Zero Shot Performance with configuration limit only")
generation_cfg_answers = [{
    'Image ID': instance['image_id'],
    'Caption': lookup[instance['image_id']][1],
    'Question': instance['question'],
    'Prompt': f"Based on the image caption (generated by BLIP model): {lookup[instance['image_id']][1]}. Answer the question: '{instance['question']}'\n Answer: ",
    'Generated Answer': llamaPipe(prompt, max_new_tokens=3)[0]['generated_text']
} for instance in tqdm(results)]

# Write data to a CSV file
pd.DataFrame(generation_cfg_answers).to_csv('10k_generation_cfg_answers.csv', index=False)

# Restriction by configuration to restrict to 3 tokens with restriction to single word in prompt
print("Running Zero Shot Performance with Restriction by configuration to restrict to 3 tokens with restriction to single word in prompt")
generation_cfg_prompt_restriction_answers = [{
    'Image ID': instance['image_id'],
    'Caption': lookup[instance['image_id']][1],
    'Question': instance['question'],
    'Prompt': f"Based on the image caption (generated by BLIP model): {lookup[instance['image_id']][1]}. Answer in a single word the question: '{instance['question']}'\n Answer: ",
    'Generated Answer': llamaPipe(prompt, max_new_tokens=3)[0]['generated_text']
} for instance in tqdm(results)]

# Write data to a CSV file
pd.DataFrame(generation_cfg_prompt_restriction_answers).to_csv('10k_generation_cfg_prompt_restriction_answers.csv', index=False)

# Configuration to generate only 3 tokens at max and Enhanced prompt
print("Running Zero Shot Performance with Restriction by Configuration to generate only 3 tokens at max and Enhanced prompt")
prompt_with_generation_cfg_answers = [{
    'Image ID': instance['image_id'],
    'Caption': lookup[instance['image_id']][1],
    'Question': instance['question'],
    'Prompt': f"Based on the image caption (generated by BLIP model): {lookup[instance['image_id']][1]}. \n In plain simple English language without any emoticons or icons or font colors or punctuation marks. I strongly state do not repeat the question, prompt used, disclaimer, explanantion or anything apart from answer, that is just provide the answer in a single word in lowercase, the question: '{instance['question']}'. Remember if you are unable to answer the question based on the caption provided by BLIP, mention 'NA'.\nAnswer: ",
    'Generated Answer': llamaPipe(prompt, max_new_tokens=3)[0]['generated_text']
} for instance in tqdm(results)]

# Write data to a CSV file
pd.DataFrame(prompt_with_generation_cfg_answers).to_csv('10k_enhanced_prompt_with_generation_cfg_answers.csv', index=False)
