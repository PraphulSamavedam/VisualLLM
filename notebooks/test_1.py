# import cv2
# files = ["COCO_val2014_000000000042.jpg", "COCO_val2014_000000000073.jpg"]

# for file in files:
#     filename = f"../data/validation/images/{file}"
#     data = cv2.imread(filename)
#     cv2.imshow('image', data)

import pandas as pd
from transformers import pipeline

# File paths
captions_file = "../data/10k_blip_captions.csv"
mapped_question_answers_file = "../data/10k_mapped_question_answers.csv"

# Load data
captions_data = pd.read_csv(captions_file)
qa_data = pd.read_csv(mapped_question_answers_file)

# Drop unnecessary column and concatenate dataframes
qa_data.drop(columns=["Image file"], inplace=True)
data = pd.concat([qa_data, captions_data], axis=1)

# Create a copy of the first 3 rows to avoid SettingWithCopyWarning
tmp_data = data[:3].copy()


llamaPipe = pipeline("text-generation", model="meta-llama/Llama-2-7b-chat-hf", device='cuda')

# Define a function to generate text
def generate_text(input_data):
    generated_text = llamaPipe(input_data, max_new_tokens=20)[0]['generated_text']
    return generated_text

tmp_data.loc[:, "Prompt"] = "Based on the image caption (generated by BLIP model): " + tmp_data['Generated Caption'] +", Answer the question " + tmp_data['Question'] +" '' \n Answer: "

# Apply the function to column 'A' of the dataframe
tmp_data.loc[:, 'Generated Answer'] = tmp_data['Prompt'].apply(generate_text)

# Write data to a CSV file
tmp_data.to_csv('tmp.csv', index=False)
